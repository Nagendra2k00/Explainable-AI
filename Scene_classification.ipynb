{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Importing required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Loading dataset paths\n",
    "train_dir = './seg_train'\n",
    "test_dir = './seg_test'\n",
    "\n",
    "# Define image size and batch size\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = image_dataset_from_directory(train_dir, shuffle=True, image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, shuffle=True, image_size=IMG_SIZE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Model definition using ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_dataset.class_names), activation='softmax')(x)  # Number of classes = 6 (buildings, forest, etc.)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of ResNet50 to avoid retraining them\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Training the model\n",
    "EPOCHS = 25\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a .h5 file\n",
    "model.save('scene_classification_model.h5')\n",
    "print(\"Model saved as 'scene_classification_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Grad-CAM Implementation\n",
    "def get_img_array(img_path, size):\n",
    "    img = load_img(img_path, target_size=size)\n",
    "    array = img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Updated Visualizing Grad-CAM with Prediction\n",
    "def display_gradcam(image_path, model, last_conv_layer_name='conv5_block3_out'):\n",
    "    img_array = get_img_array(image_path, size=IMG_SIZE)\n",
    "    \n",
    "    # Get the model prediction\n",
    "    preds = model.predict(img_array)\n",
    "    pred_class_index = np.argmax(preds[0])  # Index of predicted class\n",
    "    pred_class = train_dataset.class_names[pred_class_index]  # Predicted class name\n",
    "\n",
    "    # Display the predicted class\n",
    "    print(f\"Predicted Class: {pred_class} (confidence: {preds[0][pred_class_index] * 100:.2f}%)\")\n",
    "\n",
    "    # Generate Grad-CAM heatmap\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "\n",
    "    # Load and preprocess the original image\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Resize heatmap to match the image size\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Apply heatmap to the original image\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * 0.4 + img\n",
    "    superimposed_img = np.uint8(superimposed_img)\n",
    "\n",
    "    # Display the images\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title('Grad-CAM')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
